{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd446d21",
   "metadata": {},
   "source": [
    "# Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdea5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695d0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('USA_Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705ec481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.45857</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.80050</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208 &lt;b&gt;Michael Ferry&lt;/b&gt; Apt. 674\\nLaurabury, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.64245</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.07217</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.06718</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.15940</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.24005</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.24283</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>USS Barnett\\nFPO AP 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.19723</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.10947</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0       79545.45857             5.682861                   7.009188   \n",
       "1       79248.64245             6.002900                   6.730821   \n",
       "2       61287.06718             5.865890                   8.512727   \n",
       "3       63345.24005             7.188236                   5.586729   \n",
       "4       59982.19723             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                          4.09      23086.80050  1.059034e+06   \n",
       "1                          3.09      40173.07217  1.505891e+06   \n",
       "2                          5.13      36882.15940  1.058988e+06   \n",
       "3                          3.26      34310.24283  1.260617e+06   \n",
       "4                          4.23      26354.10947  6.309435e+05   \n",
       "\n",
       "                                             Address  \n",
       "0  208 <b>Michael Ferry</b> Apt. 674\\nLaurabury, ...  \n",
       "1  188 Johnson Views Suite 079\\nLake Kathleen, CA...  \n",
       "2  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...  \n",
       "3                          USS Barnett\\nFPO AP 44820  \n",
       "4                         USNS Raymond\\nFPO AE 09386  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28196415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Address'] = df['Address'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30af3697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.45857</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.80050</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208 &lt;b&gt;michael ferry&lt;/b&gt; apt. 674\\nlaurabury, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.64245</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.07217</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 johnson views suite 079\\nlake kathleen, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.06718</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.15940</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 elizabeth stravenue\\ndanieltown, wi 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.24005</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.24283</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>uss barnett\\nfpo ap 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.19723</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.10947</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>usns raymond\\nfpo ae 09386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0       79545.45857             5.682861                   7.009188   \n",
       "1       79248.64245             6.002900                   6.730821   \n",
       "2       61287.06718             5.865890                   8.512727   \n",
       "3       63345.24005             7.188236                   5.586729   \n",
       "4       59982.19723             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                          4.09      23086.80050  1.059034e+06   \n",
       "1                          3.09      40173.07217  1.505891e+06   \n",
       "2                          5.13      36882.15940  1.058988e+06   \n",
       "3                          3.26      34310.24283  1.260617e+06   \n",
       "4                          4.23      26354.10947  6.309435e+05   \n",
       "\n",
       "                                             Address  \n",
       "0  208 <b>michael ferry</b> apt. 674\\nlaurabury, ...  \n",
       "1  188 johnson views suite 079\\nlake kathleen, ca...  \n",
       "2  9127 elizabeth stravenue\\ndanieltown, wi 06482...  \n",
       "3                          uss barnett\\nfpo ap 44820  \n",
       "4                         usns raymond\\nfpo ae 09386  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208599c5",
   "metadata": {},
   "source": [
    "# Remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12cd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text) :\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70da9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Address'] = df['Address'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b43227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.45857</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.80050</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208  michael ferry  apt. 674\\nlaurabury,  ne  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.64245</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.07217</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 johnson views suite 079\\nlake kathleen, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.06718</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.15940</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 elizabeth stravenue\\ndanieltown, wi 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.24005</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.24283</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>uss barnett\\nfpo ap 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.19723</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.10947</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>usns raymond\\nfpo ae 09386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0       79545.45857             5.682861                   7.009188   \n",
       "1       79248.64245             6.002900                   6.730821   \n",
       "2       61287.06718             5.865890                   8.512727   \n",
       "3       63345.24005             7.188236                   5.586729   \n",
       "4       59982.19723             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                          4.09      23086.80050  1.059034e+06   \n",
       "1                          3.09      40173.07217  1.505891e+06   \n",
       "2                          5.13      36882.15940  1.058988e+06   \n",
       "3                          3.26      34310.24283  1.260617e+06   \n",
       "4                          4.23      26354.10947  6.309435e+05   \n",
       "\n",
       "                                             Address  \n",
       "0  208  michael ferry  apt. 674\\nlaurabury,  ne  ...  \n",
       "1  188 johnson views suite 079\\nlake kathleen, ca...  \n",
       "2  9127 elizabeth stravenue\\ndanieltown, wi 06482...  \n",
       "3                          uss barnett\\nfpo ap 44820  \n",
       "4                         usns raymond\\nfpo ae 09386  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d047f2",
   "metadata": {},
   "source": [
    "# Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca094a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text) :\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24322c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook https://www.kaggle.com/datasets'\n",
    "text2 = 'Check out my notebook http://www.kaggle.com/datasets'\n",
    "text3 = 'Check out my notebook www.kaggle.com/datasets'\n",
    "text4 = 'Check out my notebook https://www.kaggle.com/datasets or www.kaggle.com/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf53974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook  '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e1a699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook  '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5907440c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook  '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e53660a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook   or  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19dab2",
   "metadata": {},
   "source": [
    "# Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3759973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e52be79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0367dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text) :\n",
    "    for char in exclude :\n",
    "        text = text.replace(char, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cdf5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'string . with punctuation?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e01f0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string   with punctuation \n"
     ]
    }
   ],
   "source": [
    "print(remove_punc(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9643e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remv_punc(text) :\n",
    "    return text.translate(str.maketrans(' ' , ' ', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e19e5a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string  with punctuation\n"
     ]
    }
   ],
   "source": [
    "print(remv_punc(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3b8f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "074110ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b823b043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bfeaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = string.punctuation\n",
    "\n",
    "def remv_punc(text) :\n",
    "    return text.translate(str.maketrans(' ' , ' ', exclude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aacac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet'] = df1['tweet'].apply(remv_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "190dcf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0       RT mayasolovely As a woman you shouldnt compl...  \n",
       "1       RT mleew17 boy dats coldtyga dwn bad for cuff...  \n",
       "2       RT UrKindOfBrand Dawg RT 80sbaby4life You eve...  \n",
       "3         RT CGAnderson vivabased she look like a tranny  \n",
       "4       RT ShenikaRoberts The shit you hear about me ...  \n",
       "...                                                  ...  \n",
       "24778  yous a muthafin lie 8220LifeAsKing 20Pearls co...  \n",
       "24779  youve gone and broke the wrong heart baby and ...  \n",
       "24780  young buck wanna eat dat nigguh like I aint fu...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  Ruffled  Ntac Eileen Dahlia  Beautiful color c...  \n",
       "\n",
       "[24783 rows x 7 columns]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28fc3214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' RT mayasolovely As a woman you shouldnt complain about cleaning up your house amp as a man you should always take the trash out'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['tweet'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a9e30",
   "metadata": {},
   "source": [
    "# Chat word treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c044d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "'CU' : 'See You',\n",
    "'CUL8R' : 'See You Later',\n",
    "'CYA' : 'See You',\n",
    "'FAQ' : 'Frequently Asked Questions',\n",
    "'FC' : 'Fingers Crossed',\n",
    "'FWIW' : 'For What Its Worth',\n",
    "'FYI' : 'For Your Information',\n",
    "'GAL' : 'Get A Life',\n",
    "'GG' : 'Good Game',\n",
    "'GN' : 'Good Night',\n",
    "'GMTA' : 'Great Minds Think Alike',\n",
    "'GR8' : 'Great',\n",
    "'G9' : 'Genius',\n",
    "'IC' : 'I See'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f34968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    new_text = []\n",
    "    for w in text.split() :\n",
    "        if w.upper() in chat_words :\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else :\n",
    "            new_text.append(w)\n",
    "        \n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56e7990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Your Information Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation('FYI Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e71bee",
   "metadata": {},
   "source": [
    "# Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad40bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abf94782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c6f0d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain condition during several generation are modified in the same manner'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = 'ceertain condition during seveal ggenaration arre modified in the same maner'\n",
    "x = TextBlob(incorrect_text)\n",
    "x.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa589e",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7729a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7996e6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ed231c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text) :\n",
    "    new_text = []\n",
    "    for word in text.split() :\n",
    "        \n",
    "        if word in stopwords.words('english') :\n",
    "            new_text.append(' ')\n",
    "        else :\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "555e6a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    Nafisa Tabassum.       Cat.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('i am Nafisa Tabassum. i have a Cat.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bba2cb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0       RT mayasolovely As a woman you shouldnt compl...  \n",
       "1       RT mleew17 boy dats coldtyga dwn bad for cuff...  \n",
       "2       RT UrKindOfBrand Dawg RT 80sbaby4life You eve...  \n",
       "3         RT CGAnderson vivabased she look like a tranny  \n",
       "4       RT ShenikaRoberts The shit you hear about me ...  \n",
       "...                                                  ...  \n",
       "24778  yous a muthafin lie 8220LifeAsKing 20Pearls co...  \n",
       "24779  youve gone and broke the wrong heart baby and ...  \n",
       "24780  young buck wanna eat dat nigguh like I aint fu...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  Ruffled  Ntac Eileen Dahlia  Beautiful color c...  \n",
       "\n",
       "[24783 rows x 7 columns]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f63887d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        RT mayasolovely As   woman   shouldnt complain...\n",
       "1        RT mleew17 boy dats coldtyga dwn bad   cuffin ...\n",
       "2        RT UrKindOfBrand Dawg RT 80sbaby4life You ever...\n",
       "3             RT CGAnderson vivabased   look like   tranny\n",
       "4        RT ShenikaRoberts The shit   hear     might   ...\n",
       "                               ...                        \n",
       "24778    yous   muthafin lie 8220LifeAsKing 20Pearls co...\n",
       "24779    youve gone   broke   wrong heart baby   drove ...\n",
       "24780    young buck wanna eat dat nigguh like I aint fu...\n",
       "24781                  youu got wild bitches tellin   lies\n",
       "24782    Ruffled Ntac Eileen Dahlia Beautiful color com...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e02cd",
   "metadata": {},
   "source": [
    "# Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81acc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols And Pictographs\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ca7c4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i loved the movie  '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emojis('i loved the movie 😀 😍')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c7cdc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is  :fire:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Python is  🔥'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efc063",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d10a9b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Dhaka']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to Dhaka'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67d75cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My name is Nafisa Tabassum',\n",
       " 'I am a computer science student',\n",
       " ' I love working with technologies']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2 = 'My name is Nafisa Tabassum.I am a computer science student. I love working with technologies'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "032da27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Dhaka!']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function \n",
    "sent3 = 'I am going to Dhaka!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53b79bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Dhaka']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent4 = \"I am going to Dhaka!\"\n",
    "tokens = re.findall(\"[\\w]+\", sent4)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3310953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply',\n",
       " 'dummy text of the printing and typesetting industry',\n",
       " 'Lorem Ipsum has been the industrys',\n",
       " 'standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book',\n",
       " 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged',\n",
       " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent5 = 'Lorem Ipsum is simply! dummy text of the printing and typesetting industry. Lorem Ipsum has been the industrys? standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.'\n",
    "text = re.compile('[.!?] ').split(sent5)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "917e4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5391ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'I live in Dhaka'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3036e68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'live', 'in', 'Dhaka']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a875e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5 = 'Lorem Ipsum is simply! dummy text of the printing and typesetting industry. Lorem Ipsum has been the industrys? standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c342062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply!',\n",
       " 'dummy text of the printing and typesetting industry.',\n",
       " 'Lorem Ipsum has been the industrys?',\n",
       " 'standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.',\n",
       " 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.',\n",
       " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64a144c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent6 = \"You can connect me on tnafisa18@gmail.com\" #problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "889118ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'can', 'connect', 'me', 'on', 'tnafisa18', '@', 'gmail.com']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "740caae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent7 = 'it will cost ou 150$ for 2km.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b8bfe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'will', 'cost', 'ou', '150', '$', 'for', '2km', '.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52401ad5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dataclass_transform() got an unexpected keyword argument 'field_specifiers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \u001b[38;5;66;03m# one of the best\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\thinc\\__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m ]\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\thinc\\config.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mregistry\u001b[39;00m(confection\u001b[38;5;241m.\u001b[39mregistry):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     optimizers: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m     schedules: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschedules\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m     layers: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m     losses: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\__init__.py:2\u001b[0m, in \u001b[0;36minit pydantic.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\dataclasses.py:46\u001b[0m, in \u001b[0;36minit pydantic.dataclasses\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\main.py:121\u001b[0m, in \u001b[0;36minit pydantic.main\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: dataclass_transform() got an unexpected keyword argument 'field_specifiers'"
     ]
    }
   ],
   "source": [
    "import spacy # one of the best\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c778150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d26e9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text) :\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2109d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walking walked walks\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86077980",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = \"The company is a product of shifting cultures around the 1970s and 1980s, inspiration stemming from music of the time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3c8c26b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the compani is a product of shift cultur around the 1970 and 1980s, inspir stem from music of the time.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40409894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentance = 'He was running and eating at the same time. He has bad habit of swimming after playing long hours in the sun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7aa9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
